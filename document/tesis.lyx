#LyX 1.4.3 created this file. For more info see http://www.lyx.org/
\lyxformat 245
\begin_document
\begin_header
\textclass book
\begin_preamble
\renewcommand\[{\begin{equation}}
\renewcommand\]{\end{equation}} 
\end_preamble
\language english
\inputencoding auto
\fontscheme default
\graphics default
\paperfontsize default
\spacing single
\papersize letterpaper
\use_geometry true
\use_amsmath 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\leftmargin 3cm
\topmargin 3cm
\rightmargin 3cm
\bottommargin 5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip smallskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\end_header

\begin_body

\begin_layout Title
Paralell Training of Linear Transductive 
\begin_inset ERT
status collapsed

\begin_layout Standard

{SVM}
\end_layout

\end_inset

s for Automated Text Categorization
\end_layout

\begin_layout Author
\begin_inset ERT
status collapsed

\begin_layout Standard

DRAFT
\backslash

\backslash
 
\backslash

\backslash
 
\backslash

\backslash
 
\backslash

\backslash
 
\end_layout

\begin_layout Standard

\end_layout

\end_inset

 Miguel Fernando Cabrera Granados
\begin_inset ERT
status open

\begin_layout Standard


\backslash

\backslash
mfcabrer@unal.edu.co
\end_layout

\begin_layout Standard

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash

\backslash
 
\backslash

\backslash
 
\backslash

\backslash
 
\backslash

\backslash
 
\backslash

\backslash
 
\backslash

\backslash

\end_layout

\begin_layout Standard

Advisor
\backslash

\backslash

\end_layout

\begin_layout Standard

Jairo Jos
\backslash
'{e} Espinosa  
\backslash

\backslash
 
\backslash

\backslash
 
\backslash

\backslash
 
\backslash

\backslash
 
\backslash

\backslash

\end_layout

\begin_layout Standard

Presented in Partial Fulfillment 
\backslash

\backslash
 
\end_layout

\begin_layout Standard

of the Requirements 
\backslash

\backslash

\end_layout

\begin_layout Standard

for the Degree of 
\backslash

\backslash

\end_layout

\begin_layout Standard

Ingeniero de Sistemas e Inform
\backslash
'{a}tica 
\backslash

\backslash
 
\backslash

\backslash
 
\backslash

\backslash
 
\end_layout

\begin_layout Standard

Escuela de Sistemas - Facultad de Minas
\backslash

\backslash

\end_layout

\begin_layout Standard

Universidad Nacional de Colombia - Sede Medell
\backslash
'{i}n
\backslash

\backslash

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset LatexCommand \tableofcontents{}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Standard
GENERAL NOTES:
\end_layout

\begin_layout Standard
* When in Transductive take the example of web un-categorized data.
\end_layout

\begin_layout Standard
Find application of text categorization (Joachims Mentions many)
\end_layout

\begin_layout Standard
* In Information retrieval justify the usage of automatic techiques using
 the citation on the CMU Phd Thesis.
\end_layout

\begin_layout Standard
* Justify the usage of SVM for text classification for the reason exhibited
 in Sebastini's survey
\end_layout

\begin_layout Standard
* Justify the paralellization because collobert paper about generalization
 improvement through paralellization (CITE THEM)
\end_layout

\begin_layout Standard
* The Thesis of This girl check out the part of Text Representation and
 Empirical Risk Minization Principle
\end_layout

\begin_layout Standard
* Say in Paralell SVM that the parallelization of is difficult cause the
 dependency of the steps altoguh there have been approach to deal with this
 problem (Zanni paper)
\end_layout

\begin_layout Standard
* Change the parallell part of a review fof the tendency of parallell multicore
 processors and HPC systems.
 and basic parallelization vector and paraellization
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Overview
\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
Text classification is a key aspect of text filtering, document management
 and retrieval tasks.
 Besides basic document classification for somekind of digital library,
 many problems can be seen as instances of the Text Categorization (TC)
 problem .
 Spam detection, Web search improvement and automated metadata generation
 are just a few examples of this
\begin_inset Note Note
status collapsed

\begin_layout Standard
of the tasks that can be accomplished using automatic techniques for document
 classification
\end_layout

\end_inset

 
\begin_inset LatexCommand \cite{Sebastiani02}

\end_inset

.
 
\begin_inset Note Note
status collapsed

\begin_layout Standard
Add here the fact that the manual classification is at best expensive or
 impossible.
 Also add more examples of automated categorization usages
\end_layout

\end_inset

 Some of those tasks can be achieved by human
\emph on
 
\emph default
beings, but a manual classification is at best expensive and practically
 impossible for large amounts of documents found today in modern information
 systems.
\end_layout

\begin_layout Standard
A TC technique uses example documents that have been previously categorized
 in classes by an authority in order to learn a model that, with an associated
 error value, can automatically predict the class that the authority would
 have given to future documents.
 
\end_layout

\begin_layout Standard
Support Vector Machines 
\begin_inset LatexCommand \cite{Vapnik98}

\end_inset

 are a powerful tool for classifying large datasets, and due the nature
 of the classical text representation models, it has been applied successfully
 in automated document classification tasks 
\begin_inset LatexCommand \cite{Joachims98}

\end_inset


\begin_inset LatexCommand \cite{Joachims99c}

\end_inset

.
 An special type of SVM, based on transductive inference (TSVM), has demonstrate
d to be more effective for document classification than the common inductive
 inference based SVMs 
\begin_inset LatexCommand \cite{Joachims99c}

\end_inset

.
\end_layout

\begin_layout Standard
One characteristic of the SVM is that, in its formal definition, the computation
 and storage requirements increase rapidly with the number of training vectors.
 This is due the fact that the SVM classification problem is a Quadratic
 Programming problem (QP) that finds the support vectors in all training
 dataset.
 Solvers of this kind of problem generally scales to 
\begin_inset Formula $O(n^{3})$
\end_inset

 making it a very computationally expensive problem.
\end_layout

\begin_layout Standard
One approach to cope with this limitation is to divide the problem into
 chunks 
\begin_inset LatexCommand \cite{Joachims/99a}

\end_inset


\begin_inset LatexCommand \cite{osunaetal97}

\end_inset

 and train those subproblems.
 Even with these optimizations, the problem still has large computational
 requirements, and the required time to train grows sufficiently enough
 for making it not useful for real-time training when using large datasets.
 The implementation of Transductive inference for a SVM requires to solve
 the same problem many times over generally large datasets, until finding
 the optimal classifier.
 This makes the scaling problem for transductive SVM even more difficult,
 therefore, methods for optimizing the training process have to be developed.
\end_layout

\begin_layout Standard
Taking advantage actual trends in processor technologies, where the multi-core
 processor is becoming the norm[CitationHere] 
\begin_inset LatexCommand \cite{Marowka07}

\end_inset

 parallel implementation of such algorithm along with other optimization
 will help make the application of this technique practical in real world
 situations.
 Also, as an extra motivation, empirical results have showed that some parallel
 settings for SVM have achieved better generalization than their classic
 counterparts 
\begin_inset LatexCommand \cite{citeulike:935557|Collobert2002}

\end_inset

.
\end_layout

\begin_layout Standard
This work describes an implementation of a parallel SVM using the cascade
 model described in 
\begin_inset LatexCommand \cite{GrafCBDV04}

\end_inset

 using a transductive learning algortithm.
 The first part, Overview introduces the basic concepts a Machine Learning,
 Information Retrieval and Text Categorization.
 Later we describe the SVM algorithm and justify the reason of using SVM
 for text classification over other techniques.
 In chapter 
\begin_inset LatexCommand \vref{cha:Experiments-and-Results}

\end_inset

 we exhibit our experimental set-up and the results.
\end_layout

\begin_layout Section
Machine Learning
\end_layout

\begin_layout Standard
Machine Learning (
\noun on
ML
\noun default
) is concerned with the question of how to construct computer programs that
 automatically improve with experience 
\begin_inset LatexCommand \cite{Mitchell97}

\end_inset

.
 The experience encounter by the computer program are examples that it takes
 as input.
 In order to to develop such programs 
\noun on
ML
\noun default
 borrows concepts from many areas suchs Statistics, Information Theory,
 Biology and Control Theory, futhermore, given the amount of statistical
 based ML algorithms developed in the last years, many scientists see ML
 as a crossroad between Statistics and Computer Science.
 The learning problem is defined formally in 
\begin_inset LatexCommand \cite{Mitchell97}

\end_inset

 as follows:
\end_layout

\begin_layout Description
Learning: A computer program is said to 
\emph on
learn 
\emph default
from experience 
\begin_inset Formula $E$
\end_inset

 with respect to some class of Task 
\begin_inset Formula $T$
\end_inset

 and performace measuer 
\begin_inset Formula $P$
\end_inset

, if its performace at tasks in 
\begin_inset Formula $T$
\end_inset

, as measured by 
\begin_inset Formula $P$
\end_inset

 improves with 
\begin_inset Formula $E$
\end_inset

.
 
\begin_inset Note Note
status collapsed

\begin_layout Standard

\end_layout

\end_inset


\end_layout

\begin_layout Standard
In other words, the program learns from an experience commonly represented
 by a group of data belonging to a universe on which the result of Task
 
\begin_inset Formula $T$
\end_inset

 is known.
 Using this information the computer program tries to generalize for over
 the available data, thus learning a representation of the universe.
 
\end_layout

\begin_layout Standard
The way in which an actual computer program realizes the task of learning
 from the experience can different, there are serveral modes in which the
 learning task can be accomplished 
\begin_inset LatexCommand \cite{citeulike:755348|Heibrich2001Lkernel}

\end_inset

:
\end_layout

\begin_layout Itemize

\emph on
Supervised Learning
\emph default
: In wich the program generates an internal representation that maps inputs,
 to desired ouputs.
 Classification problems can be seen as an instance of this type of learning,
 where the desired output is a binary value stating wheter the input belongs
 to a specific category.
\end_layout

\begin_layout Itemize

\emph on
Unsupervised Learning: 
\emph default
Combines both labeled and unlabeled examples to generate the representation.
\end_layout

\begin_layout Itemize

\emph on
Reinforcement Learning
\emph default
: In wich the algorithm learns a policy of how to act given an observation
 of the world.
\end_layout

\begin_layout Standard
Besides these three main ways of learning, there are others that can be
 seen as variations of the ones mentioned above.
\end_layout

\begin_layout Itemize

\emph on
Semi-supevised Learning
\emph default
: Combines both labeled and unlabeled examples to generate the representation.
\end_layout

\begin_layout Itemize

\emph on
Transductive Learning
\emph default
: Similar to Semi-supervised Learning, but does not explicitly construct
 a function: instead, tries to predict new outputs based on training inputs,
 training outputs and test input wich are available while training.

\emph on
 
\end_layout

\begin_layout Standard
In this thesis we are going to use a restricted definition in order to ilustrate
 the concepts described above.
 In these pages machine learning will refer to a generalized regression
 characterizing a set of label events 
\begin_inset Formula $\left\{ (x_{1},y_{1}),(x_{2},y_{2}),...,(x_{n},y_{n})\right\} $
\end_inset

 with a function 
\begin_inset Formula $\Phi:X\rightarrow Y$
\end_inset

 from event to label .
 Many researcher has used this setting with success 
\begin_inset LatexCommand \cite{Berger2001}

\end_inset

 .
 The reader will notice the similarity between this definition and the definitio
n of text categorization described in section 
\begin_inset LatexCommand \vref{sec:Text-Categorization}

\end_inset

.
 
\end_layout

\begin_layout Standard
The question of how good the function 
\begin_inset Formula $\Phi$
\end_inset

 can generalize has spawned an entire subfield of machine learning called
 computational learning theory.
 Many of the techniques classified in this field have come from development
 of frameworks in this particular subfield.
 These frameworks generally don't state how good is going to perform an
 algorithm, instead create a probabilistic bound to the performace.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Standard
characterizing a set of labeled events f(x1; y1); (x2; y2); : : : (xn; yn)g
 with a function : X ! Y from event to label (or 
\backslash
output").
\end_layout

\end_inset

 Some of techniques generally classified under ML are Artificial Neural
 Networks, Genetics Algorithm, k-Nearest Neighbor, Bayesian Networks and
 and Support Vector Machines (SVM).
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Standard
* overview
\end_layout

\begin_layout Standard
* Learning taxonomy
\end_layout

\begin_layout Standard
Machine learning algorithms are organized into a taxonomy, based on the
 desired outcome of the algorithm.
 Common algorithm types include:
\end_layout

\begin_layout Standard
* Supervised learning ? in which the algorithm generates a function that
 maps inputs to desired outputs.
 One standard formulation of the supervised learning task is the classification
 problem: the learner is required to learn (to approximate) the behavior
 of a function which maps a vector [X_1, X_2, 
\backslash
ldots X_N]
\backslash
, into one of several classes by looking at several input-output examples
 of the function.
 * Unsupervised learning ? which models a set of inputs: labeled examples
 are not available.
 * Semi-supervised learning ? which combines both labeled and unlabeled
 examples to generate an appropriate function or classifier.
 * Reinforcement learning ? in which the algorithm learns a policy of how
 to act given an observation of the world.
 Every action has some impact in the environment, and the environment provides
 feedback that guides the learning algorithm.
 * Transduction ? similar to supervised learning, but does not explicitly
 construct a function: instead, tries to predict new outputs based on training
 inputs, training outputs, and test inputs which are available while training.
 * Learning to learn ? in which the algorithm learns its own inductive bias
 based on previous experience.
\end_layout

\begin_layout Standard
The computational analysis of machine learning algorithms and their performance
 is a branch of theoretical computer science known as computational learning
 theory.
\end_layout

\begin_layout Standard
* differences 
\end_layout

\begin_layout Standard
* statistical machine learning
\end_layout

\begin_layout Standard
* the natural application of machine learning to information retrieval
\end_layout

\end_inset


\end_layout

\begin_layout Section
Information Retrieval
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Standard
Information Retrieval (IR) is branch of computer science whose originally
 objective was to obtain information, only text in early stages, from generally
 large amounts of data.
 Information Retrieval (IR) is very big term that comprises a lot of concepts
 regarding data manipulation, where data can be anything from text to videos.
 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Information Retrieval (IR) is branch of computer science whose original
 objective was to obtain information from generally large amounts of data.
 Today modern IR deals with content-based document managment task, no only
 including retrieval, but also document filtering, translation and summarization
 as well.
 These last task can be seen as "Knowledge" retrieval
\end_layout

\begin_layout Standard
Altough we could generalize document to be any kind of data such as video,
 music and images, in this document when we refer to IR we will be refereing
 to text based documents.
\end_layout

\begin_layout Subsection
Models of Text and Text Representation
\end_layout

\begin_layout Subsection
Dimensionality Reduction
\end_layout

\begin_layout Section
Text Categorization
\begin_inset LatexCommand \label{sec:Text-Categorization}

\end_inset


\end_layout

\begin_layout Standard
The goal of text categorization is to automatically assign, for each documents,
 categories selected among a predefined set.
 In opposition to the machine learning typical multi-class classification
 task which aims at attributing one class among the possible ones to each
 example, documents in a text categorization task may belong to several
 categories 
\end_layout

\begin_layout Subsection
Applications of Text Categorization
\end_layout

\begin_layout Subsection
Taxonomy of Text Categorization Techniques
\end_layout

\begin_layout Subsection
Techniques
\end_layout

\begin_layout Section
Parallelization Methods
\end_layout

\begin_layout Standard
The current society of information is facing a new challenge: Thousand of
 Megabytes of information are available not only in the public Internet
 but also in private networks.
 This information is used continuously, but tools for accessing and manipulation
 of data do not fulfil the expectations of the users, hence efficient tools
 are becoming a necessity.
 Text classification becomes a key tool in order to deal with such amounts
 of information.
 Text classification can be used to organize document databases, filter
 Spam from e-mail accounts, or even to learn user?s news reading preferences.
 Search engines for On-line information are a kind of text classifier but
 they often retrieve results far from ?perfect?.
 Most of the results obtained are irrelevant, and in many case the number
 of results and their ranking is far from the desired criteria.
 Techniques derived from Artificial Intelligence and Machine-learning theory
 have contributed to the improvement of such search engines, leading to
 better, faster and more accurate results.
 Kernel methods have become one reliable and robust technique well suited
 to deal with high dimensional problems, ideal for facing text-mining tasks.
 More precisely, the Support Vector Machines have been tested in such tasks
 leading to interesting results.
 These results have been obtained based on the paradigm of Inductive Inference.
 This report contains the results of an application of Support Vector Machines
 to text classification, but now based on the paradigm of Transductive Inference.
 Section 3 summarizes the theoretical background needed to understand how
 Transductive Support Vector Machines (TSVM) work and how they can be used
 to classify text.
 Section 4 includes the different test made in order to evaluate the performance
 of the TSVM algorithm.
 Finally, section 5 presents conclusions and recommendations drawn from
 the realisation of this project.
\end_layout

\begin_layout Standard
A text classification algorithm uses example documents that have been tagged
 with classes by an authority1 to learn a model that, with high accuracy,
 can automatically predict the class the authority would have assigned to
 future documents.
 In cases like topic classification (Figure 1.1) where each example can belong
 to multiple topics, the problem is usually reduced to a series of binary
 classification tasks, Corporate Acquisitions vs.
 not Corporate Acquisitions, Earnings vs.
 not Earnings, etc.
 
\end_layout

\begin_layout Subsection
Tools
\end_layout

\begin_layout Chapter
Text Categorization With SVM
\end_layout

\begin_layout Section
Support Vector Machines
\end_layout

\begin_layout Standard
Support Vector Machines (SVMs) 
\begin_inset LatexCommand \cite{Vapnik98}

\end_inset

 are powerful classification and regresion tools that have been widely applied
 in the solutions of many problem, generally yielding comparable or even
 better performance that other algortihms.
 
\end_layout

\begin_layout Standard
The SVM algorithm is based in the principle of empirical risk minimization
 developed by Vapnik 
\begin_inset LatexCommand \cite{Vapnik98}

\end_inset


\begin_inset LatexCommand \cite{Vapnik99}

\end_inset

, the main idea of the principle is to find an hypothesis 
\begin_inset Formula $h$
\end_inset

 from an hypothesis space 
\begin_inset Formula $H$
\end_inset

 for which the lowest probability of error is guaranteed for a given set
 of training examples.
 For classification problems this is equivalent to find the discrimination
 function that maximizes the distances within the classes, assuring the
 lowerst probability of error.
 The aim of the Support Vector classification is to devise a computationally
 efficient way of learning the optimal separating hyperplanes in high dimensiona
l feature space 
\begin_inset LatexCommand \cite{citeulike:114719|Cristianini2000introSVM}

\end_inset

, defining optimal hyperplane as the one that has both, the minimum empirical
 risk and VC dimension.
 
\begin_inset LatexCommand \cite{citeulike:368926|Haykin1998}

\end_inset

.
 
\end_layout

\begin_layout Subsection
Finding the Optimal Hyperplane
\end_layout

\begin_layout Standard
Let us consider a training sample 
\begin_inset Formula $\{(x_{i},d_{i})\}_{i=1}^{N}$
\end_inset

, where x is a point in 
\begin_inset Formula $\mathbb{R}^{n}$
\end_inset

 that belongs to the group of training examples or input patterns for 
\begin_inset Formula $i$
\end_inset

th example and 
\begin_inset Formula $d_{i}$
\end_inset

 is the corresponded, desired response.
 In this case we are gonna simplifly the setting by stating that 
\begin_inset Formula $d_{i}$
\end_inset

 can only take two values 
\begin_inset Formula $\{+1,-1\}$
\end_inset

 for the positive and negative classification case respectively.
 This is case of a binary classification problem, for multiclass classification
 problem as described back in [INT-REF HERE] we can transform the problem
 in different binary classification ones.
 We also assume that the class represented by 
\begin_inset Formula $d_{i}=\{+1,-1\}$
\end_inset

 are lineary separable.
 The equation of a decision hyperplane that separates the data is:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{equation}
w^{T}x+b=0\label{eq:}\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Standard
\align center
\begin_inset Graphics
	filename images/svms-1-basic.jpg
	scale 50

\end_inset


\end_layout

\begin_layout Caption
The circles are the training data, the filled ones for 
\begin_inset Formula $d_{i}=+1$
\end_inset

 class and the empty ones for the 
\begin_inset Formula $d_{i}=-1$
\end_inset

 class.
 The points on 
\begin_inset Formula $H1$
\end_inset

 and 
\begin_inset Formula $H2$
\end_inset

 are the support vector that maximize the distance between the data and
 the hyperplane defined by 
\begin_inset Formula $w$
\end_inset

, a normal vector to the hyperplane and the offset 
\begin_inset Formula $-b/|w|$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\newpage

\end_layout

\begin_layout Standard
Where 
\begin_inset Formula $x$
\end_inset

 is an input vector, 
\begin_inset Formula $w$
\end_inset

 is the weight vector, normal to the separation hyperplane, and 
\begin_inset Formula $b$
\end_inset

 is the offset or bias:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{multline*}
\\w^{T}x+b\geq0\mbox{\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,}for\,\,\,\,\,\,\, d_{i}=+1\\
\\w^{T}x+b<0\mbox{\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,}for\,\,\,\,\,\,\, d_{i}=-1\\
\\\end{multline*}

\end_inset


\end_layout

\begin_layout Standard
For a given vector 
\begin_inset Formula $w$
\end_inset

 and offset 
\begin_inset Formula $b$
\end_inset

 the distance between the the hyperplane defined in and a point 
\begin_inset Formula $x$
\end_inset

 is called margin of separation represented by the equation
\begin_inset LatexCommand \ref{eq:}

\end_inset

.
\end_layout

\begin_layout Standard
Then we can write the discriminat function:
\end_layout

\begin_layout Standard
\begin_inset Formula \begin{equation}
{g(x)=w}^{T}x+b\label{eq:2}\end{equation}

\end_inset


\end_layout

\begin_layout Standard
This equation gives a mesuare of the distance from x to the optimal hyperplane,
 in order 
\end_layout

\begin_layout Section
SVM and Text Categorization
\end_layout

\begin_layout Standard
The usage of SVM was first introduced by Joachims 
\begin_inset LatexCommand \cite{Joachims98}

\end_inset


\begin_inset LatexCommand \cite{Joachims99c}

\end_inset

 and similar setups have been used in posterior literature[CITATIONS HERE!]
 .
 the TC task using SVM can bee seen geometrically as finding an hyperplane
 that separates two grous of points has 
\end_layout

\begin_layout Subsection
Linear SVM for Text Categorization
\end_layout

\begin_layout Subsection
Transductive Learning for SVM
\end_layout

\begin_layout Subsection
Linear Transductive Learning SVM for Text Categorization
\end_layout

\begin_layout Section
Paralell Method for Training Transuductive SVM
\end_layout

\begin_layout Subsection
Transductive Parallel Linear SVM
\end_layout

\begin_layout Chapter
Experiments and Results
\begin_inset LatexCommand \label{cha:Experiments-and-Results}

\end_inset


\end_layout

\begin_layout Section
Experimental Setting
\end_layout

\begin_layout Subsection
Software
\end_layout

\begin_layout Subsection
Data Sets
\end_layout

\begin_layout Subsection
The Cascade SVM
\end_layout

\begin_layout Standard
For the experiment we use cascade SVM 
\begin_inset LatexCommand \cite{GrafCBDV04}

\end_inset

 
\end_layout

\begin_layout Section
Results
\end_layout

\begin_layout Section
Conclusions
\end_layout

\begin_layout Standard
\begin_inset LatexCommand \bibtex[acm]{bibblio}

\end_inset


\end_layout

\end_body
\end_document
