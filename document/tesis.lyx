#LyX 1.4.3 created this file. For more info see http://www.lyx.org/
\lyxformat 245
\begin_document
\begin_header
\textclass book
\begin_preamble

\end_preamble
\language english
\inputencoding auto
\fontscheme default
\graphics default
\paperfontsize 12
\spacing single
\papersize letterpaper
\use_geometry true
\use_amsmath 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\leftmargin 3cm
\topmargin 3cm
\rightmargin 3cm
\bottommargin 5cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\defskip medskip
\quotes_language swedish
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\end_header

\begin_body

\begin_layout Title
Paralell Training of Transductive SVMs for Automated Document Categorization
\end_layout

\begin_layout Author
Miguel Cabrera Granados
\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash

\backslash
mfcabrer@unal.edu.co
\backslash

\backslash

\end_layout

\begin_layout Standard

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Standard


\backslash
it School of Informatics and Systems
\backslash

\backslash

\end_layout

\begin_layout Standard


\backslash
it National University of Colombia - Campus Medellín
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Introduction
\end_layout

\begin_layout Standard
Text classification is a key aspect of text filtering and document managment
 and retrieval tasks.
 Spam detection, web search improvement, automated metadata generation,
 are just a few examples of the tasks that can be accomplished using automatic
 techniques for document classification
\begin_inset LatexCommand \cite{Sebastiani02}

\end_inset

.
\begin_inset Note Note
status collapsed

\begin_layout Standard
Add here the fact that the manual classification is at best expensive or
 impossible.
 Also add more examples of automated categorization usages
\end_layout

\end_inset

 Support Vector Machine
\begin_inset LatexCommand \cite{Vapnik99}

\end_inset

 is a powerful tool for classifiying large datasets, and due the nature
 of the common text representation model, it has been applied succesfuly
 for automated document classification
\begin_inset LatexCommand \cite{Joachims98}

\end_inset

.
 An especial type of SVM, based on transductive inference has demostrated
 being more effective for document classification than the common inductive
 inference based SVMs
\begin_inset LatexCommand \cite{Joachims99c}

\end_inset

.
\end_layout

\begin_layout Standard
One characteristic of the SVM is that in it's formal definition the computation
 and storage requirements increase rapidly with the number of training vectors.
 This is due the fact that the SVM classification problem is a Quadratic
 Programming problem (QP) that finds the support vectors in all training
 dataset.
 Solvers of this kind of problem generally scales to 
\begin_inset Formula $O(n^{3})$
\end_inset

 making it a very computationally expensive problem.
\end_layout

\begin_layout Standard
An approach to cope with this limitation is to divide the problem into chunks
 
\begin_inset LatexCommand \cite{Joachims/99a}

\end_inset


\end_layout

\begin_layout Standard
The current society of information is facing a new challenge: Thousand of
 Megabytes of information are available not only in the public Internet
 but also in private networks.
 This information is used continuously, but tools for accessing and manipulation
 of data do not fulfil the expectations of the users, hence efficient tools
 are becoming a necessity.
 Text classification becomes a key tool in order to deal with such amounts
 of information.
 Text classification can be used to organize document databases, filter
 Spam from e-mail accounts, or even to learn user?s news reading preferences.
 Search engines for On-line information are a kind of text classifier but
 they often retrieve results far from ?perfect?.
 Most of the results obtained are irrelevant, and in many case the number
 of results and their ranking is far from the desired criteria.
 Techniques derived from Artificial Intelligence and Machine-learning theory
 have contributed to the improvement of such search engines, leading to
 better, faster and more accurate results.
 Kernel methods have become one reliable and robust technique well suited
 to deal with high dimensional problems, ideal for facing text-mining tasks.
 More precisely, the Support Vector Machines have been tested in such tasks
 leading to interesting results.
 These results have been obtained based on the paradigm of Inductive Inference.
 This report contains the results of an application of Support Vector Machines
 to text classification, but now based on the paradigm of Transductive Inference.
 Section 3 summarizes the theoretical background needed to understand how
 Transductive Support Vector Machines (TSVM) work and how they can be used
 to classify text.
 Section 4 includes the different test made in order to evaluate the performance
 of the TSVM algorithm.
 Finally, section 5 presents conclusions and recommendations drawn from
 the realisation of this project.
\end_layout

\begin_layout Standard
\begin_inset LatexCommand \bibtex[acm]{bibblio}

\end_inset


\end_layout

\end_body
\end_document
