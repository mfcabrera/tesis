TODO:
Write:
- Precition and recall function
- Error Calculation


Expermimentation.

Dataset: 20 News Group

Task
-------
Easy task
Hard Task
Computationally Hard Task(*) (Optional)



Each task will be tested with
------------------------------
Many Labels
Just a fraction with original labels 

and with 3 differents methodologies
-----------------------------------
(C Determined by K-Fold Crossvalidation of the Testing SET when needed)
Linear SVM Paralell 
Linear Transductive SVM 
Paralell transductive


Easy Task: (2000 DOCUMENTS HALF POSTIVE AND HALF NEGATIVE)
Groups 
com.hardware
vs
atheism (25% For training and 75% For testing)
	Manylabels: 1000 labeled and 1000 unalabeled for testing
	Few labels: 200 labeled 1800 unlabeld for testing


Hard Task: (2000 DOCUMENTS HALF POSTIVE AND HALF NEGATIVE)
Groups 
com.hardware.mac
vs
com.hardware.pc
	Manylabels: 1000 labeled and 1000 unalabeled for testing
	Few labels: 200 labeled 1800 unlabeld for testing



Number of Experiments:
2*2*3 = 12

Sample Table
-------------
                 EASY TASK          |        HARD TASK
  
                    P|R|F        |        P|R|F
C-SVM (C=n)
TSVM  (C,Caskt)
P-TSVM (C,Caskt)




Performance Measures
-------------------
		95 						100	
		95						200		

	recall = Number of items of category correctly identified / Number of category members in test set
	precision = Number of items of category correctly identified / Total items assigned to category (Correct and Incorrect)



		Precisition and Recall 


Many evaluation criteria for classification have been proposed. 
The most popular measures are based on precision and recall. Precision is the proportion of items
placed in the category that are really in the category, and Recall is the proportion of items in the category that are
actually placed in the category. We report the average of precision and recall (the so-called breakeven point) for
comparability to earlier results in text classification. 
In addition, we plot precision as a function of recall in order to understand the relationship among methods at different
points along this curve. Table 2 summarizes microaveraged break even performance for the 5 different learning algorithms for the 10 most frequent categories as
well as the overall score for all 118 categories.



Primer experimento pseudo largo.

n =

        1850


ntest =

        1500


ri =

    0.9440


pi =

    0.9986


fi =

    0.9705


rt =

    0.9867


pt =

    0.9867


ft =

    0.9867


1) ATH VS CG
--------------
2000
1000 Positive
1000 Negative

20% Training
80% Testing

Results

ri =

    0.9988


pi =

    0.9744


fi =

    0.9864


rtp =

    0.9900


ptp =

    0.9900


ftp =

    0.9900








